"""
Model Loader - Ã‡oklu hisse senedi modelini yÃ¼kle ve cache'le
"""
import os
import pickle
import numpy as np
from tensorflow import keras
from typing import Optional, Tuple
import logging
import json

logger = logging.getLogger(__name__)


class ModelLoader:
    """ML Model yÃ¼kleme ve cache servisi (Ã§oklu sembol desteÄŸiyle)"""
    
    def __init__(self, base_dir: str = "models/artifacts", symbol: str = "V"):
        """
        Args:
            base_dir (str): Model artifactlarÄ±nÄ±n bulunduÄŸu ana klasÃ¶r
            symbol (str): Hisse sembolÃ¼ (Ã¶r: 'V', 'WMT')
        """
        self.base_dir = base_dir
        self.symbol = symbol.upper()
        self.artifacts_dir = os.path.join(base_dir, self.symbol)
        
        self.model = None
        self.feature_scaler = None
        self.label_scaler = None
        self.metadata = None
        self.is_loaded = False

    # -----------------------------------------------------------
    # MODEL YÃœKLEME
    # -----------------------------------------------------------
    def load_model(self) -> keras.Model:
        """Belirli bir sembole ait modeli yÃ¼kle"""
        try:
            model_path = os.path.join(self.artifacts_dir, f"{self.symbol}_model.keras")

            if not os.path.exists(model_path):
                raise FileNotFoundError(f"Model not found: {model_path}")

            logger.info(f"ðŸ“¦ Loading model from {model_path}")
            self.model = keras.models.load_model(model_path)
            logger.info("âœ… Model loaded successfully")

            return self.model

        except Exception as e:
            logger.error(f"âŒ Error loading model: {str(e)}")
            raise

    # -----------------------------------------------------------
    # SCALER YÃœKLEME
    # -----------------------------------------------------------
    def load_scalers(self) -> Tuple:
        """Feature ve target scaler'larÄ± yÃ¼kle"""
        try:
            feature_scaler_path = os.path.join(self.artifacts_dir, "scaler_X.pkl")
            label_scaler_path = os.path.join(self.artifacts_dir, "scaler_y.pkl")

            if not os.path.exists(feature_scaler_path):
                raise FileNotFoundError(f"Feature scaler not found: {feature_scaler_path}")
            if not os.path.exists(label_scaler_path):
                raise FileNotFoundError(f"Label scaler not found: {label_scaler_path}")

            with open(feature_scaler_path, "rb") as f:
                self.feature_scaler = pickle.load(f)
            with open(label_scaler_path, "rb") as f:
                self.label_scaler = pickle.load(f)

            logger.info("âœ… Scalers loaded successfully")
            return self.feature_scaler, self.label_scaler

        except Exception as e:
            logger.error(f"âŒ Error loading scalers: {str(e)}")
            raise

    # -----------------------------------------------------------
    # METADATA YÃœKLEME
    # -----------------------------------------------------------
    def load_metadata(self) -> dict:
        """Model metadata'sÄ±nÄ± yÃ¼kle"""
        try:
            metadata_path = os.path.join(self.artifacts_dir, "meta.json")

            if not os.path.exists(metadata_path):
                raise FileNotFoundError(f"Metadata file not found: {metadata_path}")

            with open(metadata_path, "r") as f:
                self.metadata = json.load(f)

            logger.info("âœ… Metadata loaded successfully")
            return self.metadata

        except Exception as e:
            logger.error(f"âŒ Error loading metadata: {str(e)}")
            raise

    # -----------------------------------------------------------
    # TÃœM ARTEFAKTLARI YÃœKLE
    # -----------------------------------------------------------
    def load_all(self) -> bool:
        """TÃ¼m artifactlarÄ± (model, scaler, metadata) yÃ¼kle"""
        try:
            logger.info(f"ðŸ”„ Loading all artifacts for symbol: {self.symbol}")
            self.load_model()
            self.load_scalers()
            self.load_metadata()

            self.is_loaded = True
            logger.info("âœ… All artifacts loaded successfully!")
            return True

        except Exception as e:
            logger.error(f"âŒ Failed to load artifacts: {str(e)}")
            self.is_loaded = False
            return False

    # -----------------------------------------------------------
    # TAHMÄ°N
    # -----------------------------------------------------------
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Scaled veriden tahmin yap ve inverse-transform uygula"""
        if not self.is_loaded:
            raise RuntimeError("Model not loaded. Call load_all() first.")
        if self.model is None:
            raise RuntimeError("Model is None")

        predictions_scaled = self.model.predict(X, verbose=0)
        predictions = self.label_scaler.inverse_transform(predictions_scaled)
        return predictions

    # -----------------------------------------------------------
    # MODEL BÄ°LGÄ°LERÄ°
    # -----------------------------------------------------------
    def get_model_info(self) -> dict:
        """Model metadata'sÄ±nÄ± dÃ¶ndÃ¼r"""
        if not self.is_loaded or self.metadata is None:
            return {"status": "not_loaded"}

        return {
            "status": "loaded",
            "symbol": self.symbol,
            "trained_on": self.metadata.get("trained_on"),
            "model_format": self.metadata.get("model_format"),
            "sequence_length": self.metadata.get("sequence_length"),
            "version": self.metadata.get("model_version", "1.0"),
        }


# -----------------------------------------------------------
# LOCAL TEST
# -----------------------------------------------------------
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    loader = ModelLoader(symbol="WMT")  # veya "V"
    
    if loader.load_all():
        info = loader.get_model_info()
        print("\nðŸ“Š Model Info:")
        for k, v in info.items():
            print(f"  {k}: {v}")

        print("\nðŸ§ª Testing dummy prediction...")
        dummy_input = np.random.rand(1, 60, 13)  # (batch, seq, features)
        pred = loader.predict(dummy_input)
        print(f"âœ… Dummy prediction: {pred[0][0]:.5f}")
